{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating NN Model\n",
    "\n",
    "Using validation curves to validate the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import activation_functions\n",
    "import loss_functions\n",
    "import process_MNIST\n",
    "from init_NN import NeuralNetwork\n",
    "\n",
    "#local path to files \n",
    "training_images_path =  'training_data/train-images.idx3-ubyte'\n",
    "training_labels_path =  'training_data/train-labels.idx1-ubyte'\n",
    "test_images_path = 'test_data/t10k-images.idx3-ubyte'\n",
    "test_labels_path =  'test_data/t10k-labels.idx1-ubyte'\n",
    "\n",
    "\n",
    "#Loads MNIST data files. Assumes unzipped idx files avilable at: http://yann.lecun.com/exdb/mnist/\n",
    "training_images, training_labels = process_MNIST.load_data(training_images_path, training_labels_path)\n",
    "test_images, test_labels = process_MNIST.load_data(test_images_path, test_labels_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model with Learning Rate 0.001 using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:26<00:00, 695.64it/s]\n",
      " 10%|█         | 1/10 [01:26<12:57, 86.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:49<00:00, 549.92it/s]\n",
      " 20%|██        | 2/10 [03:15<13:18, 99.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:32<00:00, 646.25it/s]\n",
      " 30%|███       | 3/10 [04:48<11:17, 96.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:37<00:00, 616.32it/s]\n",
      " 40%|████      | 4/10 [06:26<09:42, 97.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:35<00:00, 628.15it/s]\n",
      " 50%|█████     | 5/10 [08:01<08:02, 96.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:38<00:00, 610.64it/s]\n",
      " 60%|██████    | 6/10 [09:40<06:28, 97.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:52<00:00, 531.25it/s]\n",
      " 70%|███████   | 7/10 [11:33<05:07, 102.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:48<00:00, 551.09it/s]\n",
      " 80%|████████  | 8/10 [13:22<03:29, 104.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:08<00:00, 881.58it/s]\n",
      " 90%|█████████ | 9/10 [14:30<01:33, 93.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:06<00:00, 897.20it/s] \n",
      "100%|██████████| 10/10 [15:37<00:00, 93.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross entropy loss: 0.42922857933322484\n",
      "Classification accuracy: 89.49000000000001%\n"
     ]
    }
   ],
   "source": [
    "#Define NN architecture. Input size (first layer) and output size (last layer) can't change.\n",
    "#Will have linear activation functions between each layer, and ReLU activation functions after \n",
    "#each linear activation function except between last hidden layer and output layer. \n",
    "lsize = [784, 128, 64, 10] #e.g. this structure will have 3 linear activation functions and 2 ReLU fcns\n",
    "lr = 0.001\n",
    "\n",
    "##initialize NN \n",
    "nn_lr001_sgd = NeuralNetwork(lsize, activation_functions.ReLU, activation_functions.dReLU, loss_functions.cross_entropy_w_softmax, loss_functions.dcross_entropy, lr)\n",
    "\n",
    "##train NN (example uses mini-batch)\n",
    "nn_lr001_sgd.train(training_images, training_labels, epochs = 10, batch_size=1)\n",
    "#gradient descent means batch size = # training samples (# steps you take = # epochs)\n",
    "#stochastic gradient descent means batch size = 1\n",
    "\n",
    "##test NN\n",
    "nn_lr001_sgd_cross_ent_error, nn_lr001_sgd_classification_error = nn_lr001_sgd.test(test_images, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model with Learning Rate 0.001 using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.74s/it]\n",
      " 10%|█         | 1/10 [00:35<05:22, 35.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.76s/it]\n",
      " 20%|██        | 2/10 [01:10<04:42, 35.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:33<00:00, 33.85s/it]\n",
      " 30%|███       | 3/10 [01:44<04:02, 34.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.88s/it]\n",
      " 40%|████      | 4/10 [02:20<03:31, 35.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:33<00:00, 33.72s/it]\n",
      " 50%|█████     | 5/10 [02:54<02:53, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:37<00:00, 37.66s/it]\n",
      " 60%|██████    | 6/10 [03:32<02:23, 35.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.33s/it]\n",
      " 70%|███████   | 7/10 [04:07<01:46, 35.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.02s/it]\n",
      " 80%|████████  | 8/10 [04:43<01:11, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "lr = 0.001\n",
    "nn_lr001_gd = NeuralNetwork(lsize, activation_functions.ReLU, activation_functions.dReLU, loss_functions.cross_entropy_w_softmax, loss_functions.dcross_entropy, lr)\n",
    "nn_lr001_gd.train(training_images, training_labels, epochs = 10, batch_size=len(training_images))\n",
    "nn_lr001_gd_cross_ent_error, nn_lr001_gd_classification_error = nn_lr001_sgd.test(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "nn_lr01_sgd = NeuralNetwork(lsize, activation_functions.ReLU, activation_functions.dReLU, loss_functions.cross_entropy_w_softmax, loss_functions.dcross_entropy, lr)\n",
    "nn_lr01_sgd.train(training_images, training_labels, epochs = 10, batch_size=1)\n",
    "nn_lr01_sgd_cross_ent_error, nn_lr001_sgd_classification_error = nn_lr001_sgd.test(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_lr01_gd = NeuralNetwork(lsize, activation_functions.ReLU, activation_functions.dReLU, loss_functions.cross_entropy_w_softmax, loss_functions.dcross_entropy, lr)\n",
    "nn_lr01_gd.train(training_images, training_labels, epochs = 10, batch_size=len(training_images))\n",
    "nn_lr01_gd_cross_ent_error, nn_lr001_gd_classification_error = nn_lr001_sgd.test(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
