{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating NN Model\n",
    "\n",
    "Using validation curves to validate the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import activation_functions\n",
    "import loss_functions\n",
    "import process_MNIST\n",
    "from init_NN_val import NeuralNetwork\n",
    "\n",
    "#local path to files \n",
    "training_images_path =  'training_data/train-images.idx3-ubyte'\n",
    "training_labels_path =  'training_data/train-labels.idx1-ubyte'\n",
    "test_images_path = 'test_data/t10k-images.idx3-ubyte'\n",
    "test_labels_path =  'test_data/t10k-labels.idx1-ubyte'\n",
    "\n",
    "\n",
    "#Loads MNIST data files. Assumes unzipped idx files avilable at: http://yann.lecun.com/exdb/mnist/\n",
    "training_images, training_labels = process_MNIST.load_data(training_images_path, training_labels_path)\n",
    "test_images, test_labels = process_MNIST.load_data(test_images_path, test_labels_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model with Learning Rate 0.001 using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:50<00:00, 50.89s/it]\n",
      " 10%|█         | 1/10 [00:51<07:39, 51.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:54<00:00, 54.62s/it]\n",
      " 20%|██        | 2/10 [01:45<07:05, 53.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:00<00:00, 60.47s/it]\n",
      " 30%|███       | 3/10 [02:46<06:36, 56.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:58<00:00, 58.84s/it]\n",
      " 40%|████      | 4/10 [03:45<05:45, 57.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:03<00:00, 63.92s/it]\n",
      " 50%|█████     | 5/10 [04:49<04:59, 59.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:06<00:00, 66.26s/it]\n",
      " 60%|██████    | 6/10 [05:56<04:08, 62.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:01<00:00, 62.00s/it]\n",
      " 70%|███████   | 7/10 [06:58<03:06, 62.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:04<00:00, 64.98s/it]\n",
      " 80%|████████  | 8/10 [08:03<02:06, 63.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:55<00:00, 55.43s/it]\n",
      " 90%|█████████ | 9/10 [08:59<01:00, 60.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:57<00:00, 57.10s/it]\n",
      "100%|██████████| 10/10 [09:56<00:00, 59.64s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn_lr001_sgd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m nn_lr01_gd \u001b[39m=\u001b[39m NeuralNetwork(lsize, activation_functions\u001b[39m.\u001b[39mReLU, activation_functions\u001b[39m.\u001b[39mdReLU, loss_functions\u001b[39m.\u001b[39mcross_entropy_w_softmax, loss_functions\u001b[39m.\u001b[39mdcross_entropy, lr)\n\u001b[0;32m      5\u001b[0m nn_lr01_gd\u001b[39m.\u001b[39mtrain(training_images, training_labels, epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(training_images))\n\u001b[1;32m----> 6\u001b[0m nn_lr01_gd_cross_ent_error, nn_lr001_gd_classification_error \u001b[39m=\u001b[39m nn_lr001_sgd\u001b[39m.\u001b[39mtest(test_images, test_labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn_lr001_sgd' is not defined"
     ]
    }
   ],
   "source": [
    "lsize = [784, 128, 64, 10] #e.g. this structure will have 3 linear activation functions and 2 ReLU fcns\n",
    "lr = 0.01\n",
    "\n",
    "nn_lr01_gd = NeuralNetwork(lsize, activation_functions.ReLU, activation_functions.dReLU, loss_functions.cross_entropy_w_softmax, loss_functions.dcross_entropy, lr)\n",
    "losses = nn_lr01_gd.train(training_images, training_labels, epochs = 10, batch_size=len(training_images))\n",
    "nn_lr01_gd_cross_ent_error, nn_lr001_gd_classification_error = nn_lr01_gd.test(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross entropy loss: 100.30918349962414\n",
      "Classification accuracy: 42.54%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Cross Entropy Loss vs. Epoch with LR=0.01 and using GD')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
